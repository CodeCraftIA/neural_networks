# neural_networks
The provided code demonstrates how to load and preprocess the MNIST dataset using Keras and scikit-learn, then train and evaluate models using k-Nearest Neighbors (kNN) and Multilayer Perceptrons (MLPs) for handwritten digit classification.

# Key Steps in the Code:
Data Loading and Preprocessing:

Load the MNIST dataset.
Reshape and normalize the data for use in machine learning models.
# k-Nearest Neighbors (kNN):
Train and evaluate kNN classifiers with 1 and 3 neighbors.
Train and evaluate a Nearest Centroid classifier.
Compare the accuracy of the models.

# Multilayer Perceptrons (MLPs):
Train various MLP architectures with different numbers of layers and neurons.
Experiment with dropout layers to mitigate overfitting.
Visualize the training and validation loss to assess model performance.
